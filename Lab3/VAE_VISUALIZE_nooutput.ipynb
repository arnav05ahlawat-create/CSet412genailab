{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlq0Ws0YAfhF"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/VAE_Project_lab3\"\n",
        "plots_dir = base_dir + \"/plots\"\n",
        "samples_dir = base_dir + \"/samples\"\n",
        "models_dir = base_dir + \"/models\"\n",
        "\n",
        "os.makedirs(plots_dir, exist_ok=True)\n",
        "os.makedirs(samples_dir, exist_ok=True)\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "print(\"Folders created successfully!\")\n"
      ],
      "metadata": {
        "id": "LQmP4NPLAjOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "iO_0mDEdAlJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "epochs = 20\n",
        "latent_dim = 2   # keep 2 for visualization\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "Lb0W8Y6sAlHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(\"Dataset loaded!\")\n"
      ],
      "metadata": {
        "id": "YaYN9LSwAlFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc_mu = nn.Linear(400, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(400, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mu, logvar\n"
      ],
      "metadata": {
        "id": "JUFhrMrGAlDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 400)\n",
        "        self.fc2 = nn.Linear(400, 784)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = torch.relu(self.fc1(z))\n",
        "        x_recon = torch.sigmoid(self.fc2(z))\n",
        "        return x_recon\n"
      ],
      "metadata": {
        "id": "bTma7kd2AlBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_recon = self.decoder(z)\n",
        "        return x_recon, mu, logvar\n"
      ],
      "metadata": {
        "id": "wxH0UmRWAktm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(x_recon, x, mu, logvar):\n",
        "    recon_loss = nn.functional.binary_cross_entropy(x_recon, x, reduction='sum')\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kl_loss\n"
      ],
      "metadata": {
        "id": "uTWM9KgQA7aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = []\n"
      ],
      "metadata": {
        "id": "SVsojAs9A7UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.view(-1, 784).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        x_recon, mu, logvar = model(data)\n",
        "        loss = loss_function(x_recon, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    losses.append(avg_loss)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "wvROocvHA_BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "\n",
        "plot_path = plots_dir + \"/training_loss.png\"\n",
        "plt.savefig(plot_path)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved:\", plot_path)\n"
      ],
      "metadata": {
        "id": "sgcZBABKBAqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "latent_vectors = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in train_loader:\n",
        "        data = data.view(-1, 784).to(device)\n",
        "        mu, logvar = model.encoder(data)\n",
        "        latent_vectors.append(mu.cpu())\n",
        "        labels.append(target)\n",
        "\n",
        "latent_vectors = torch.cat(latent_vectors)\n",
        "labels = torch.cat(labels)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(latent_vectors[:,0], latent_vectors[:,1], c=labels, cmap='tab10', s=5)\n",
        "plt.colorbar()\n",
        "plt.title(\"Latent Space\")\n",
        "\n",
        "latent_plot_path = plots_dir + \"/latent_space.png\"\n",
        "plt.savefig(latent_plot_path)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved:\", latent_plot_path)\n"
      ],
      "metadata": {
        "id": "naG113ZFBCGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    z = torch.randn(16, latent_dim).to(device)\n",
        "    samples = model.decoder(z).cpu()\n",
        "\n",
        "samples = samples.view(16, 1, 28, 28)\n",
        "\n",
        "fig, axes = plt.subplots(4,4, figsize=(5,5))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(samples[i][0], cmap=\"gray\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "sample_path = samples_dir + \"/generated_samples.png\"\n",
        "plt.savefig(sample_path)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved:\", sample_path)\n"
      ],
      "metadata": {
        "id": "teNqW5A5BDpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = models_dir + \"/vae_model.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(\"Model saved at:\", model_path)\n"
      ],
      "metadata": {
        "id": "hS1_BHH5BFFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "data_iter = iter(train_loader)\n",
        "images, _ = next(data_iter)\n",
        "\n",
        "images = images.view(-1, 784).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    recon_images, mu, logvar = model(images)\n",
        "\n",
        "images = images.cpu().view(-1,1,28,28)\n",
        "recon_images = recon_images.cpu().view(-1,1,28,28)\n",
        "\n",
        "n = 8  # number of samples to display\n",
        "\n",
        "fig, axes = plt.subplots(2, n, figsize=(15,4))\n",
        "\n",
        "for i in range(n):\n",
        "    axes[0,i].imshow(images[i][0], cmap=\"gray\")\n",
        "    axes[0,i].set_title(\"Original\")\n",
        "    axes[0,i].axis(\"off\")\n",
        "\n",
        "    axes[1,i].imshow(recon_images[i][0], cmap=\"gray\")\n",
        "    axes[1,i].set_title(\"Reconstructed\")\n",
        "    axes[1,i].axis(\"off\")\n",
        "\n",
        "save_path = samples_dir + \"/original_vs_reconstruction.png\"\n",
        "plt.savefig(save_path)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved:\", save_path)\n"
      ],
      "metadata": {
        "id": "VNIXYdeACH0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "\n",
        "model.eval()\n",
        "\n",
        "frames = []\n",
        "\n",
        "grid_x = np.linspace(-3, 3, 10)\n",
        "grid_y = np.linspace(-3, 3, 10)\n",
        "\n",
        "for xi in grid_x:\n",
        "    for yi in grid_y:\n",
        "        z = torch.tensor([[xi, yi]]).float().to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            sample = model.decoder(z).cpu().view(28,28)\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.imshow(sample, cmap='gray')\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Save frame temporarily\n",
        "        frame_path = \"/content/frame.png\"\n",
        "        plt.savefig(frame_path)\n",
        "        plt.close()\n",
        "\n",
        "        frames.append(imageio.imread(frame_path))\n",
        "\n",
        "gif_path = samples_dir + \"/latent_space_animation.gif\"\n",
        "imageio.mimsave(gif_path, frames, fps=5)\n",
        "\n",
        "print(\"GIF saved at:\", gif_path)\n"
      ],
      "metadata": {
        "id": "1um0Umg8Cxe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HL757HvUC3zm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}